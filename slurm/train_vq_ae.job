#!/bin/bash

#SBATCH --job-name debug-vq-ae-patches
#SBATCH -N 1
#SBATCH -t 1-00:00:00
#SBATCH -c 6
#SBATCH -p gpu_titanrtx_shared
#SBATCH -o slurm-%j-%x.out
#SBATCh -e slurm-%j-%x.out
export OMP_NUM_THREADS=6

set -e

# Flags made to be edited
DATASET_NAME="CAMELYON16-DEBUG"
DATASET_ROOT="/project/robertsc/examode/"
CONDA_ENV="2D-VQ-AE-2"

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
if [[ $SCRIPT_DIR == *"/var/spool/"* ]] && [ ! -z $SLURM_JOB_ID ]; then
    # When using slurm, while running a job script (instead of node salloc)
    SCRIPT_DIR=$( dirname $( scontrol show job $SLURM_JOB_ID | awk -F= '/Command=/{print $2}'))
fi

ROOT_DIR=$( cd "$SCRIPT_DIR"/..; pwd )
echo "- found root dir $ROOT_DIR"

if [ ! -z $SLURM_JOB_NODELIST ]; then
    NODES=( $( scontrol show hostnames "$SLURM_JOB_NODELIST" | head ) )
    NUM_NODES="${#NODES[@]}"
else
    NUM_NODES="1"
fi

echo "- setting up env"

source $ROOT_DIR/slurm/load-asap.sh

export PYTHONFAULTHANDLER=1

SCRIPTPATH="$ROOT_DIR/vq_ae/train.py"

INDIR="$TMPDIR"
if [ -z $INDIR ]; then
    MAYBE_INDIR="/scratch/slurm.$SLURM_JOB_ID.0/scratch"
    if [ ! -z $SLURM_JOB_ID ] && [ -d $MAYBE_INDIR ]; then
        INDIR=$MAYBE_INDIR
    else
        echo "- INDIR is empty!"
        exit 1
    fi
fi
echo "- using INDIR $INDIR"

DATASET_PATH="$DATASET_ROOT""$DATASET_NAME"
DATASET_INDIR="$INDIR"/"$DATASET_NAME"
echo "- assuming Dataset path $DATASET_PATH"

echo "- setting args"
PYTHON_ARGS="\
--data-dir $DATASET_INDIR \
"
echo "- found args $PYTHON_ARGS"


if (( $NUM_NODES > 1 )); then
    echo "- multi-node setup"
    echo "- copying dataset"
    mpicopy -v "$DATASET_PATH" -o $INDIR
    echo "- starting run"
    srun python "$SCRIPTPATH" $PYTHON_ARGS
else
    echo "- single-node setup"
    echo "- copying dataset"
    rsync -ah --info=progress2 "$DATASET_PATH" "$INDIR"
    echo "- starting run"
    python "$SCRIPTPATH" $PYTHON_ARGS
fi
